{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz6CwD6MRWFs"
      },
      "source": [
        "##Install Requirement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nD9uOPEK65K0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AwVn7yc7Soj"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git\n",
        "%cd /content/MedViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RPHDM3KwQ4Ys"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.9 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 7.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting medmnist\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (1.24.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.2-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 19.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp39-cp39-macosx_12_0_arm64.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 12.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting scikit-image\n",
            "  Downloading scikit_image-0.22.0-cp39-cp39-macosx_12_0_arm64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 1.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 11.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 11.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting Pillow\n",
            "  Downloading pillow-10.3.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 12.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fire\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 12.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 12.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: torch in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 13)) (2.2.2)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.18.0-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 13.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[K     |████████████████████████████████| 388 kB 12.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 11.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting safetensors\n",
            "  Downloading safetensors-0.4.3-cp39-cp39-macosx_11_0_arm64.whl (411 kB)\n",
            "\u001b[K     |████████████████████████████████| 411 kB 12.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[K     |████████████████████████████████| 345 kB 13.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[K     |████████████████████████████████| 505 kB 13.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting joblib>=1.2.0\n",
            "  Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 13.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting scipy>=1.6.0\n",
            "  Downloading scipy-1.13.0-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.3 MB 1.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tifffile>=2022.8.12\n",
            "  Downloading tifffile-2024.4.18-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 2.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from scikit-image->-r requirements.txt (line 7)) (24.0)\n",
            "Collecting imageio>=2.27\n",
            "  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
            "\u001b[K     |████████████████████████████████| 313 kB 3.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from scikit-image->-r requirements.txt (line 7)) (3.2.1)\n",
            "Collecting lazy_loader>=0.3\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting termcolor>=1.1\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 3.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from fire->-r requirements.txt (line 11)) (1.15.0)\n",
            "Collecting requests~=2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 5.4 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: sympy in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (1.12)\n",
            "Requirement already satisfied: fsspec in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (4.11.0)\n",
            "Requirement already satisfied: jinja2 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (3.1.3)\n",
            "Requirement already satisfied: filelock in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 13)) (3.13.4)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.0-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 61.0 MB 1.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 15.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 4.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 11.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting idna<3,>=2.5\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->-r requirements.txt (line 13)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from sympy->torch->-r requirements.txt (line 13)) (1.3.0)\n",
            "Building wheels for collected packages: fvcore, fire, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61433 sha256=b6ecf6f1009a7b83d8a2d3c11dfeec4a46c01a9877d9ba562487119300786ebc\n",
            "  Stored in directory: /Users/maggieyao/Library/Caches/pip/wheels/83/42/02/66178d16e5c44dc26d309931834956baeda371956e86fbd876\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117047 sha256=3a5eed6e5d3b49c70212a6c2ae2e6f001d17870c789409081abeb7d36bc0a4f8\n",
            "  Stored in directory: /Users/maggieyao/Library/Caches/pip/wheels/ec/ce/ba/9d5764d2266c500c18776c7d8f1e3c023075994cbc6dea47db\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31550 sha256=c31e43bf2f4d4e2b21af9ee2a48199f506acc6374aa2421a5c6bbe14c2ca8a5c\n",
            "  Stored in directory: /Users/maggieyao/Library/Caches/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
            "Successfully built fvcore fire iopath\n",
            "Installing collected packages: urllib3, Pillow, idna, chardet, certifi, tzdata, tqdm, torch, tifffile, threadpoolctl, termcolor, scipy, requests, pyyaml, pytz, portalocker, lazy-loader, joblib, imageio, yacs, torchvision, tabulate, scikit-learn, scikit-image, safetensors, pandas, iopath, huggingface-hub, fire, torchattacks, timm, medmnist, fvcore, einops\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.2\n",
            "    Uninstalling torch-2.2.2:\n",
            "      Successfully uninstalled torch-2.2.2\n",
            "Successfully installed Pillow-10.3.0 certifi-2024.2.2 chardet-4.0.0 einops-0.7.0 fire-0.6.0 fvcore-0.1.5.post20221221 huggingface-hub-0.22.2 idna-2.10 imageio-2.34.1 iopath-0.1.10 joblib-1.4.0 lazy-loader-0.4 medmnist-3.0.1 pandas-2.2.2 portalocker-2.8.2 pytz-2024.1 pyyaml-6.0.1 requests-2.25.1 safetensors-0.4.3 scikit-image-0.22.0 scikit-learn-1.4.2 scipy-1.13.0 tabulate-0.9.0 termcolor-2.4.0 threadpoolctl-3.4.0 tifffile-2024.4.18 timm-0.9.16 torch-2.3.0 torchattacks-3.5.1 torchvision-0.18.0 tqdm-4.66.2 tzdata-2024.1 urllib3-1.26.18 yacs-0.1.8\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 5.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.2.1-cp39-cp39-macosx_11_0_arm64.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 12.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.0)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pillow>=8 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.3.0)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 18.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.51.0-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.24.1)\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Downloading kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 15.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /Users/maggieyao/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.8.4 pyparsing-3.1.2\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lgm5vmQp8i9h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "deLoJPfDTDWl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch 2.3.0\n",
            "Torchvision 0.18.0\n",
            "Torchattacks 3.5.1\n",
            "Numpy 1.24.1\n",
            "Medmnist 3.0.1\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIefIFDW80-U"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVNzCWaVUd_1"
      },
      "source": [
        "data_flag =  \n",
        "[tissuemnist, pathmnist, chestmnist, dermamnist, octmnist, pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rH1INOxS8-iM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of channels :  3\n",
            "number of classes :  5\n"
          ]
        }
      ],
      "source": [
        "data_flag = 'retinamnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "# NUM_EPOCHS = 10\n",
        "# BATCH_SIZE = 10\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "# lr = 0.005\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(\"number of channels : \", n_channels)\n",
        "print(\"number of classes : \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TD22o8uW9L1X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /Users/maggieyao/.medmnist/retinamnist.npz\n",
            "Using downloaded and verified file: /Users/maggieyao/.medmnist/retinamnist.npz\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eNjqCTnI9T9w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset RetinaMNIST of size 28 (retinamnist)\n",
            "    Number of datapoints: 1080\n",
            "    Root location: /Users/maggieyao/.medmnist\n",
            "    Split: train\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset RetinaMNIST of size 28 (retinamnist)\n",
            "    Number of datapoints: 400\n",
            "    Root location: /Users/maggieyao/.medmnist\n",
            "    Split: test\n",
            "    Task: ordinal-regression\n",
            "    Number of channels: 3\n",
            "    Meaning of labels: {'0': '0', '1': '1', '2': '2', '3': '3', '4': '4'}\n",
            "    Number of samples: {'train': 1080, 'val': 120, 'test': 400}\n",
            "    Description: The RetinaMNIST is based on the DeepDRiD challenge, which provides a dataset of 1,600 retina fundus images. The task is ordinal regression for 5-level grading of diabetic retinopathy severity. We split the source training set with a ratio of 9:1 into training and validation set, and use the source validation set as the test set. The source images of 3×1,736×1,824 are center-cropped and resized into 3×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ta2wQYk78Mg"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a17pPgePWXga"
      },
      "source": [
        "MedViTs ---> [MedViT_small, MedViT_base, MedViT_large]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEQ5S3_U8E0j",
        "outputId": "0ea09038-9e57-42ab-b767-592098af81ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ],
      "source": [
        "from MedViT import MedViT_small, MedViT_base, MedViT_large\n",
        "\n",
        "model = MedViT_small(num_classes = n_classes).cpu()\n",
        "#model = MedViT_base(num_classes = n_classes).cuda()\n",
        "#model = MedViT_large(num_classes = n_classes).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ImKp2m9cLf"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gMy_aJrE9eeM"
      },
      "outputs": [],
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KmIo3JWf9lEs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 216/216 [11:18<00:00,  3.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 216/216 [10:59<00:00,  3.05s/it]\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cpu(), targets.cpu()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRkfM6CM91j8"
      },
      "source": [
        "##Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdC1Gg98RU37",
        "outputId": "11f6b052-2ac0-4080-c31d-cb5c4cdf0ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test  auc: 0.695  acc: 0.490\n"
          ]
        }
      ],
      "source": [
        "split = 'test'\n",
        "\n",
        "model.eval()\n",
        "y_true = torch.tensor([])\n",
        "y_score = torch.tensor([])\n",
        "\n",
        "data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in data_loader:\n",
        "        inputs = inputs.cpu()\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.softmax(dim=-1)\n",
        "        y_score = torch.cat((y_score, outputs.cpu()), 0)\n",
        "\n",
        "    y_score = y_score.detach().numpy()\n",
        "\n",
        "    evaluator = Evaluator(data_flag, split, size=224)\n",
        "    metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "    print('%s  auc: %.3f  acc: %.3f' % (split, *metrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH1WvchMX5L0"
      },
      "source": [
        "## Adversarial Robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GER2-X0Yc1ZL"
      },
      "source": [
        "reduce bach size for GPU limitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rNHm98NaZjZ5"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 5\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK4kV6p9YiZY"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = FGSM(model, eps=0.01)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('FGSM Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76g3n07lcW8x"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "atk = PGD(model, eps=8/255, alpha=4/255, steps=10, random_start=True)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    labels = labels.squeeze(1)\n",
        "    images = atk(images, labels).cuda()\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.cuda()).sum()\n",
        "\n",
        "print('PGD Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
